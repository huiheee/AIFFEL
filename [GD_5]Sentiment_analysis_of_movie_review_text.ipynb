{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 네이버 영화리뷰 감성분석 도전하기\n",
        "\n",
        "Rubric\n",
        "\n",
        "|평가문항|상세기준|\n",
        "|---|---|\n",
        "|1. 다양한 방법으로 Text Classification 태스크를 성공적으로 구현하였다.|3가지 이상의 모델이 성공적으로 시도됨|\n",
        "|2. gensim을 활용하여 자체학습된 혹은 사전학습된 임베딩 레이어를 분석하였다.|gensim의 유사단어 찾기를 활용하여 자체학습한 임베딩과 사전학습 임베딩을 비교 분석함|\n",
        "|3. 한국어 Word2Vec을 활용하여 가시적인 성능향상을 달성했다.|네이버 영화리뷰 데이터 감성분석 정확도를 85% 이상 달성함|"
      ],
      "metadata": {
        "id": "X39ofUv7J27V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opgPGFeIJLeB"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "import konlpy\n",
        "import gensim\n",
        "\n",
        "print(pandas.__version__)\n",
        "print(konlpy.__version__)\n",
        "print(gensim.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1, 데이터 준비와 확인"
      ],
      "metadata": {
        "id": "rQ9Z4knzmzRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터를 읽어봅시다. \n",
        "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
        "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
        "\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "hKn4WF-yJ-p0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 데이터로더 구성"
      ],
      "metadata": {
        "id": "_CS_rswJm19h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "tokenizer = Mecab()\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
        "\n",
        "def load_data(train_data, test_data, num_words=num_words):\n",
        "    # [[YOUR CODE]]\n",
        "    \n",
        "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
      ],
      "metadata": {
        "id": "dawcndTtJ-ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kHlJOE4jJ-ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VxaVL_oOJ-je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8W_K0-ugJ-hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8U80w0iYJ-fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ADBCXU9zJ-dN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c5eHtoe-J-Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E_Kxk832J-O_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gc-uBV_KJ-Mk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}